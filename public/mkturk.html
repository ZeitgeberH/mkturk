<!doctype html>

<head>
<meta name="mobile-web-app-capable" content="yes"> <!-- full screen https://developer.chrome.com/multidevice/android/installtohomescreen -->
<meta name="viewport" content="width=device-width, user-scalable=no"> <!-- do not allow window rescaling.  To avoid window rescaling in portrait mode, added with=device-width from http://stackoverflow.com/questions/22771523/ipad-w-retina-safari-reported-dimensions-in-landscape-make-no-sense -->

<link rel="manifest" href="mkturkmanifest.json">
<link rel="icon" href="mkturklogo48.png">

<script src="https://unpkg.com/dropbox/dist/Dropbox-sdk.min.js"></script>
<script src="utils.js"></script>

<!-- <script src="mkturkdropbox.js" type="text/javascript"></script>
<script src="mkturkautomator.js" type="text/javascript"></script>
<script src="mkturkble.js" type="text/javascript"></script> -->

<script src="mkturk_usersettings.js"></script>
<script src="mkturk_screenfunctions.js"></script>

</head>

<!-- ************* BODY *************** -->
<body bgcolor=#7F7F7F>
<div id="canvasdiv" style="position:relative; width:100vw; height:100vh">
	<button name="connectble" style="visibility:hidden; position: absolute; top: 45%; left: 45%; height: 100px; width: 200px; border-radius: 20px">Connect to Bluetooth juicer</button>
	<button name="noble" style="visibility:hidden; position: absolute; top: 55%; left: 45%; height: 100px; width: 200px; border-radius: 20px">No Bluetooth juicer</button>

	<p id="headsuptext" style="z-index:99; position: absolute; left: 1px; top: 1px; height: 40%; width: 60%; font-size: 20px; color: white; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;"></p>

	<button name="doneEditing" style="visibility:hidden; position: absolute; top: 45%; left: 70%; height: 100px; width: 100px; border-radius: 20px">Done editing params</button>

	<button name="doneTesting" style="visibility:hidden; position: absolute; top: 55%; left: 70%; height: 100px; width: 200px; border-radius: 20px; z-index:101">Done with testing</button>

	<canvas id="canvasheadsup" width="0" height="0" src="" style="z-index:98; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas0" width="0" height="0" src="" style="z-index:99; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas1" width="0" height="0" src="" style="z-index:1; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas2" width="0" height="0" src="" style="z-index:2; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas3" width="0" height="0" src="" style="z-index:3; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas4" width="0" height="0" src="" style="z-index:4; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas5" width="0" height="0" src="" style="z-index:5; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas6" width="0" height="0" src="" style="z-index:6; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvas7" width="0" height="0" src="" style="z-index:7; position: absolute; left: 0px; top: 0px;"> </canvas>
	<canvas id="canvascapture" width="0" height="0" src="" style="z-index:0; position: absolute; left: 0px; top: 0px;"> </canvas>
</div>
<dialog id="subjectID_dialog">
  <p>Select subject: </p>
 
   <!--Pull down menu that will hold file list-->
  <select id="subjectID_list">
  	<option value="-1">--</option>
  </select>
</dialog>

<script src="mkturk_eventlisteners.js" type="text/javascript"></script>
<script src="mkturk_globalvariables.js"></script>
<script src="mkturk_dropbox.js" type="text/javascript"></script>
<script src="mkturk_ImageBuffer.js" type="text/javascript"></script>
<script src="mkturk_TrialQueue.js" type="text/javascript"></script>
<script src="mkturk_automator.js" type="text/javascript"></script>
<script src="mkturk_hardware.js" type="text/javascript"></script>


<script>
//================== AUTHENTICATE ==================//
if (isAuthenticated()){
	//Create an instance of Dropbox with the access token
	var dbx = new Dropbox({accessToken: getAccessTokenFromUrl()})
}
else {
	var dbx = new Dropbox({clientId: DBX_CLIENT_ID});
	var dbx_authUrl = dbx.getAuthenticationUrl(DBX_REDIRECT_URI);
	window.location.href = dbx_authUrl //send to Dropbox sign-in screen
}


// GET PARAMFILE NAME
var subjectdialog = document.getElementById("subjectID_dialog");
var subjectlistobj = document.getElementById("subjectID_list");
for (var i=subjectlist.length-1; i>=0; i--){
	var opt = document.createElement('option');
	opt.value = i;
	opt.innerHTML = subjectlist[i];
	subjectlistobj.appendChild(opt);
}
subjectlistobj.addEventListener("change",subjectlist_listener,false);

// Button callbacks
document.querySelector("button[name=connectble]").addEventListener(
	'touchend',findBLEDevice,false)
document.querySelector("button[name=connectble]").addEventListener(
	'mouseup',findBLEDevice,false)
document.querySelector("button[name=noble]").addEventListener(
	'touchend',skipBLEDevice,false)
document.querySelector("button[name=noble]").addEventListener(
	'mouseup',skipBLEDevice,false)
document.querySelector("button[name=doneEditing]").addEventListener(
	'touchend',doneEditing_listener,false)
document.querySelector("button[name=doneEditing]").addEventListener(
	'mouseup',doneEditing_listener,false)
document.querySelector("button[name=doneTesting]").addEventListener(
	'touchend',doneTesting_listener,false)
document.querySelector("button[name=doneTesting]").addEventListener(
	'mouseup',doneTesting_listener,false)
var textobj = document.getElementById("headsuptext")
textobj.addEventListener('touchend',headsuptext_listener,false)
textobj.addEventListener('mouseup',headsuptext_listener,false)
//================== Initialize Screen/Audio/Video ==================//
	// Prevent window scrolling and bounce back effect
	document.body.addEventListener('touchmove',function(event){
		event.preventDefault();
	}, false);
	//Audio pulses for reward
	var audiocontext = new (window.AudioContext || window.webkitAudioContext)();
	var gainNode = audiocontext.createGain()
	gainNode.connect(audiocontext.destination)
	var devicePixelRatio = window.devicePixelRatio || 1;
	var visiblecanvasobj = document.getElementById("canvas" + CANVAS.front);
	var visiblecontext = visiblecanvasobj.getContext("2d");
	var backingStoreRatio = visiblecontext.webkitBackingStorePixelRatio ||
	                            visiblecontext.mozBackingStorePixelRatio ||
	                            visiblecontext.msBackingStorePixelRatio ||
	                            visiblecontext.oBackingStorePixelRatio ||
	                            visiblecontext.backingStorePixelRatio || 1;
	var canvasScale = devicePixelRatio/backingStoreRatio;
	
	//Monitor Battery - from: http://www.w3.org/TR/battery-status/
	navigator.getBattery().then(function(batteryobj){
		battery.ldt[battery.current]=[batteryobj.level, batteryobj.dischargingTime, Math.round(performance.now())];
		battery.current++;
		batteryobj.addEventListener('levelchange',function(){
			battery.ldt[battery.current]=[batteryobj.level, batteryobj.dischargingTime, Math.round(performance.now())];
			battery.current++;
		})
	});
//================== Initialize Screen/Audio/Video (end) ==================//
// issues for top-level code using async: https://github.com/tc39/ecmascript-asyncawait/issues/9
(async function(){
	//================== CONNECT TO BLE ==================//
	document.querySelector("button[name=connectble]").style.display = "block"
	document.querySelector("button[name=connectble]").style.visibility = "visible"
	document.querySelector("button[name=noble]").style.display = "block"
	document.querySelector("button[name=noble]").style.visibility = "visible"
	await connectBLEButtonPromise()
	document.querySelector("button[name=connectble]").style.display = "none" //if do style.visibility=hidden, element will still occupy space
	document.querySelector("button[name=noble]").style.display = "none"
	
	subjectdialog.showModal();
	await subjectIDPromise();	
	ENV.paramfile = PARAM_DIRPATH + ENV.subjectID + "_params.txt";
	await loadParametersfromDropbox(ENV.paramfile);

	//================== USER CAN EDIT PARAMS ==================//
	ble.statustext = await loadTextFilefromDropbox(ENV.paramfile)
	updateStatusText(ble.statustext)
	document.querySelector("p[id=headsuptext]").setAttribute("contentEditable",true)
	document.querySelector("button[name=doneEditing]").style.display = "block"
	document.querySelector("button[name=doneEditing]").style.visibility = "visible"
	
	await editParamsPromise()
	document.querySelector("button[name=doneEditing]").style.display = "none"
	var textobj = document.getElementById("headsuptext")
	textobj.removeEventListener('touchend',headsuptext_listener)
	textobj.removeEventListener('mouseup',headsuptext_listener)
	document.querySelector("p[id=headsuptext]").setAttribute("contentEditable",false)

	if (FLAGS.need2writeParameters == 1){
		var user_param_text = document.getElementById("headsuptext").innerHTML 		
		await writeParameterTexttoDropbox(user_param_text) 
		await loadParametersfromDropbox(ENV.paramfile);
	}

	updateStatusText('Loading images...')

	
	//================== TEST MODE ==================//
	FLAGS.savedata = 0
	document.querySelector("button[name=doneTesting]").style.display = "block"
	document.querySelector("button[name=doneTesting]").style.visibility = "visible"

	// Read performance history
	var subject_behavior_save_directory = DATA_SAVEPATH + ENV.subjectID + '/'
	var history_file_paths = await getMostRecentBehavioralFilePathsFromDropbox(ndatafiles2read, ENV.subjectID, subject_behavior_save_directory)
	trialhistory = await readTrialHistoryFromDropbox(history_file_paths);
	// Initialize automator - change TASK to that specified by TASK.automatorStage. 
	if (TASK.automator != 0){
		automator_data = await parseAutomatorFilefromDropbox(TASK.automatorFilePath) 
		automateTask(automator_data, trialhistory) 
		await saveParameterstoDropbox() 
		await loadParametersfromDropbox(ENV.paramfile); 

		// Preload stuff now (to ensure smooth transitions between automator stages)
		var AutomatorPreBuffer = {}; 
		AutomatorPreBuffer['TrialQueue'] = {}; 
		
		console.log('Starting to populate automator prebuffer:')

		
		for (var a = TASK.automatorStage; a < automator_data.length; a++){
			console.time('Stage '+a)

			// Make TrialQueue
			var samplingStrategy = 'uniform_with_replacement' // todo: add more options; move into TASK
			AutomatorPreBuffer['TrialQueue'][a] = new TrialQueue(samplingStrategy, automator_data[a].imageBagsSample, automator_data[a].imageBagsTest); 

			var num_prebuffer_trials = 30; 
			await AutomatorPreBuffer['TrialQueue'][a].build(num_prebuffer_trials); 
			console.timeEnd('Stage '+a)
		}
		console.log('Done prebuffering')
	}

	//Load sounds
	soundpromises = sounds.serial.map(loadSoundfromDropbox2); //create array of sound load Promises
	await Promise.all(soundpromises); //simultaneously evaluate array of sound load promises
	updateStatusText("")

	

// =========================================================================================================== // 
// ============ MAIN LOOP ==================================================================================== // 
// =========================================================================================================== // 
FLAGS.need2loadParameters = 1
FLAGS.current_trial = 0; 
FLAGS.sampleblockcount = 0; 
FLAGS.need2loadImages = 1; 

while(true){
		
	if (FLAGS.need2writeParameters == 1){
		saveParameterstoDropbox(); 
		FLAGS.need2writeParameters = 0; 
	}

	if (FLAGS.need2loadParameters == 0){
		FLAGS.need2loadParameters = checkParameterFileStatus()
	}

	if (FLAGS.need2loadParameters == 1){
		var old_imageBagsSample = TASK.imageBagsSample
		var old_imageBagsTest = TASK.imageBagsTest
		await loadParametersfromDropbox(ENV.paramfile);
		FLAGS.need2loadParameters = 0; 	

		// Check if images were changed
		if(!old_imageBagsTest.equals(TASK.imageBagsTest) || !old_imageBagsSample.equals(TASK.imageBagsSample)){
			FLAGS.need2loadImages = 1; 
		}
		
	}

	// Update canvas based on latest TASK state: 
	refreshCanvasSettings(TASK); 
	setupCanvasHeadsUp()
	windowWidth = window.innerWidth; 
	windowHeight = window.innerHeight;
	
	for (i = 0; i <= CANVAS.punish; i++) {
		setupCanvas(i);
	}

	if (devicePixelRatio !== 1){
		scaleCanvasforHiDPI(CANVAS.sample);
		scaleCanvasforHiDPI(CANVAS.test);
	}


	if (FLAGS.purge == 1){
		purgeTrackingVariables()
		FLAGS.purge = 0; 
	}

	//============ IMAGE LOADING ============//
	if (FLAGS.need2loadImages == 1){
		console.time('Image loading time:')

		if(TASK.automator != 1){
			// Load filenames manually from Dropbox
			var funcreturn = await loadImageBagPaths(TASK.imageBagsSample); 
			samplebag_paths = funcreturn[0]
			samplebag_labels = funcreturn[1]

			var funcreturn = await loadImageBagPaths(TASK.imageBagsTest); 
			testbag_paths = funcreturn[0]
			testbag_labels = funcreturn[1]

			// Make TrialQueue
			var samplingStrategy = 'uniform_with_replacement' // todo: add more options; move into TASK
			TQ = new TrialQueue(samplingStrategy, samplebag_labels, samplebag_paths, testbag_labels, testbag_paths)
			TQ.build(1); 
		}	

		else if(TASK.automator == 1){
			TQ = AutomatorPreBuffer.TrialQueue[TASK.automatorStage]
			samplebag_paths = TQ.samplebag_paths
			testbag_paths = TQ.testbag_paths
		}
		
		FLAGS.need2loadImages = 0;
		console.timeEnd('Image loading time:')
		ENV.ordered_samplebag_filenames = samplebag_paths; 
		ENV.ordered_testbag_filenames = testbag_paths; 
	} 

	renderReward();
	renderPunish();
	

	//============ BUFFER SAMPLE & TEST (for next trial) ============//

	console.time('trial images loadtime:')
	var [trial_sampleimage, trial_sampleImage_index, trial_testimages, trial_testImage_indices, trial_correctItem_index] = await TQ.get_next_trial(); 
	console.timeEnd('trial images loadtime:')


	// Write down dimensions of (assumedly) all images in samplebag and testbag, based on this sample image. 
	var representative_image = trial_sampleimage
	ENV.wd = representative_image.width
	ENV.ht = representative_image.height
	// Make image display grid
	funcreturn = defineImageGrid(TASK.ngridpoints, ENV.wd, ENV.ht, TASK.sampleScale, canvasScale); 
	xgrid = funcreturn[0]
	ygrid = funcreturn[1]
	xgridcent = funcreturn[2]
	ygridcent = funcreturn[3]
	if(FLAGS.savedata == 0){
		// In test mode show grid on screen
		renderBlankWithGridMarkers(); 
	}
	else if (FLAGS.savedata == 1){
		renderBlank();
	}


	await bufferTrialImages(trial_sampleimage, TASK.sampleGrid, trial_testimages, TASK.testGrid, trial_correctItem_index);
	//============ RUN FIXATION SCREEN ============//
	
	// If no fixation requirement: 

	if (TASK.fixationDur <= 0){
		FLAGS.waitingforFixation=0
		trial_fixationGrid =-1;
		trial_tstart = Math.round(performance.now());
		trial_xytfixation =[-1,-1,trial_tstart];
	}

	else if (TASK.fixationDur > 0){
		FLAGS.waitingforFixation=1;
	}

	while (FLAGS.waitingforFixation==1){

		// Choose fixation grid index at random
		if (TASK.fixationMove > 0){
			trial_fixationGrid = Math.floor((xgrid.length)*Math.random()); 
		}
		else if (TASK.fixationMove == 0){
			trial_fixationGrid = TASK.fixationGrid;
		}

		// Render fixation screen 
		FLAGS.stage=0;

		if (TASK.fixationUsesSample == 1){
			renderFixationUsingImage(trial_sampleimage, TASK.fixationGrid, TASK.sampleScale)
		}
		else if(TASK.fixationUsesSample != 1){
			if (TASK.species == "macaque" || TASK.species == "human"){
				var color = "white";
			}
			else if (TASK.species == "marmoset"){
				var color = "blue";
			}
			renderFixationUsingDot(color, TASK.fixationGrid, TASK.fixationRadius);
		}
		

		// Start timer for this fixation render trial. 
		trial_tstart =Math.round(performance.now());
		frame.shown=[];
		for (var q in CANVAS.sequencepre){
			frame.shown[q]=0
		}; 
		frame.current=0;

		// todo: move to appropriate location
		if (TASK.species == 'marmoset'){
			playSound(0);
		}

		await displayTrial(CANVAS.sequencepre,CANVAS.tsequencepre);
		audiocontext.suspend()
		await fixationPromise();
		for (var q in CANVAS.sequenceblank){
			frame.shown[q]=0
		}; 
		frame.current=0;
	} 

	//============ RUN SAMPLE & TEST SCREEN ============//
	FLAGS.stage=1;
	// Show sample (then) test:
	if (TASK.rewardStage === 1){
		frame.shown=[];
		
		for (var q in CANVAS.sequence){
			frame.shown[q]=0
		}; 

		frame.current=0;
		await displayTrial(CANVAS.sequence,CANVAS.tsequence);
		audiocontext.suspend()
		await responsePromise();
		FLAGS.waitingforResponse=0;
	}

	//============ REWARD/PUNISH SCREEN ============//
	

	FLAGS.stage=2;
	frame.shown=[];
	for (var q in CANVAS.sequencepost){frame.shown[q]=0}; frame.current=0;

	// Fixation task reward/punish screens
	ENV.reward = setReward(); 
	if (TASK.rewardStage === 0){
		if (FLAGS.brokeFixation == 0){
			trial_response = trial_correctItem_index;
			CANVAS.sequencepost[1]=CANVAS.photoreward;
			CANVAS.sequencepost[2]=CANVAS.reward;
			CANVAS.tsequencepost[2] = CANVAS.tsequencepost[1]+ENV.reward*1000;
			//console.log('Touched fixation - reward')
		}
		else if (FLAGS.brokeFixation == 1){
			trial_response = -1;
			CANVAS.sequencepost[1]=CANVAS.punish;
			CANVAS.sequencepost[2]=CANVAS.punish;
			CANVAS.tsequencepost[2] = TASK.punish;
			//console.log('Touched outside fixation - punish')
		}
	} // Choice task reward/punish screens
	else if (TASK.rewardStage === 1){ 
		if (trial_response == trial_correctItem_index){
			CANVAS.sequencepost[1]=CANVAS.photoreward;
			CANVAS.sequencepost[2]=CANVAS.reward;
			CANVAS.tsequencepost[2] = CANVAS.tsequencepost[1]+ENV.reward*1000;
			//console.log('Trial correct - reward.')
		} 
		else { 
			CANVAS.sequencepost[1]=CANVAS.punish;
			CANVAS.sequencepost[2]=CANVAS.punish;
			CANVAS.tsequencepost[2] = TASK.punish;
			//console.log('Trial incorrect! - punished.')
		}

		if (FLAGS.current_trial>0){
			if (trial_response==trialhistory.correct[trialhistory.correct.length-1]){
				FLAGS.stickyresponse++;
			}
			else {
				FLAGS.stickyresponse=0;
			}
		}
	} 

	console.log('response:', trial_response)
	console.log('correct response', trial_correctItem_index)

	// Calculate number of rewards to give
	if (trial_response == trial_correctItem_index && 
		(FLAGS.current_trial==0 || 
		(TASK.rewardStage==0 && 
			trial_tstart - trialhistory.tstart[trialhistory.tstart.length - 1] < TASK.consecutivehitsITI) || 
		(TASK.rewardStage==1 && 
			trial_tstart - trialhistory.tstart[trialhistory.tstart.length - 1]  < TASK.consecutivehitsITI))){
			
			FLAGS.consecutivehits++
			trial_nreward = 1 + Math.floor(FLAGS.consecutivehits / TASK.nconsecutivehitsforbonus)
		if (trial_nreward > TASK.nrewardmax){
			trial_nreward = TASK.nrewardmax
		}
	}
	else {
		if (trial_response == trial_correctItem_index){
			FLAGS.consecutivehits=1;
			trial_nreward = 1;
		}
		else if (trial_response != trial_correctItem_index){
			FLAGS.consecutivehits=0;
			trial_nreward = 0;
		}	
	}
	// console.log('nhits: ' + FLAGS.consecutivehits + ', nreward: ' + trial_nreward)
	
	// Deliver reward or punishment
	frame.shown=[];
	for (var q in CANVAS.sequencepost){frame.shown[q]=0}; frame.current=0;
	if (CANVAS.sequencepost[1]==CANVAS.photoreward && TASK.species == 'marmoset'){
		for (var q = 0; q <= trial_nreward-1; q++){
			frame.shown=[];
			for (var q2 in CANVAS.sequencepost){frame.shown[q2]=0}; frame.current=0;
			await playSound(2); 
			var p1 = displayTrial(CANVAS.sequencepost,CANVAS.tsequencepost)
			if (ble.connected == false){
				await Promise.all([p1])
			}
			else if (ble.connected == true){
				var p2 = writepumpdurationtoBLE(Math.round(ENV.reward*1000))
				await Promise.all([p1, p2])
			}
		}
	} 
	if (CANVAS.sequencepost[1]==CANVAS.photoreward && (TASK.species == 'macaque' || TASK.species == "human")){
		for (var q = 0; q <= trial_nreward-1; q++){
			frame.shown=[];
			for (var q2 in CANVAS.sequencepost){frame.shown[q2]=0}; frame.current=0;
			await playSound(2);
			await displayTrial(CANVAS.sequencepost,CANVAS.tsequencepost)
			//var p2 = await dispenseReward()
			if (ble.connected == false){
				//await Promise.all([p1, p2])
			}
			else if (ble.connected == true){
				var p3 = writepumpdurationtoBLE(Math.round(ENV.reward*1000))
				await Promise.all([p1, p2, p3])
			}
		}
	} // Play pump sound
	if (CANVAS.sequencepost[1]==CANVAS.punish){
		if (TASK.species == 'marmoset'){
			playSound(3);
		}
		
		await displayTrial(CANVAS.sequencepost,CANVAS.tsequencepost);


		console.time('punish download/timeout')
		var num_trials_to_buffer_in_punishperiod = 20
		await Promise.all([dispensePunish(), TQ.generate_trials(num_trials_to_buffer_in_punishperiod)])
		console.timeEnd('punish download/timeout')
	}



	// Update TRIAL only if saving data
	FLAGS.stage=3;
	if (FLAGS.savedata == 1){
		TRIAL.automatorStage[FLAGS.current_trial] = TASK.automatorStage; 
		TRIAL.sample[FLAGS.current_trial] = trial_sampleImage_index 
		TRIAL.test[FLAGS.current_trial] = trial_testImage_indices 
		TRIAL.correctItem[FLAGS.current_trial] = trial_correctItem_index
		TRIAL.tstart[FLAGS.current_trial] = trial_tstart
		TRIAL.xytfixation[FLAGS.current_trial] = trial_xytfixation
		TRIAL.fixationGrid[FLAGS.current_trial] = trial_fixationGrid
		TRIAL.response[FLAGS.current_trial] = trial_response
		TRIAL.xytresponse[FLAGS.current_trial] = trial_xytresponse
		TRIAL.nreward[FLAGS.current_trial] = trial_nreward

		// Update trialhistory 
		var current_stage = stageHash(TASK); 
		trialhistory.trainingstage.push(current_stage); 
		trialhistory.tstart.push(trial_tstart)

		if (TASK.rewardStage==0 & FLAGS.brokeFixation==0){
			trialhistory.correct.push(1);
		}
		if (TASK.rewardStage==0 & FLAGS.brokeFixation==1){
			trialhistory.correct.push(0);
		}
		if (TASK.rewardStage==1 & TRIAL.response[FLAGS.current_trial] == TRIAL.correctItem[FLAGS.current_trial]){
			trialhistory.correct.push(1);
		}
		else if (TASK.rewardStage==1) {
			trialhistory.correct.push(0);
		}

		// Run automator
		if (TASK.automator !=0){	
			await automateTask(automator_data, trialhistory);
		}

		// Save data
		if(FLAGS.need2writeBehavior == 1){
			writeBehaviortoDropbox(TASK, ENV, TRIAL); 		
		}		
	}

	updateHeadsUpDisplay(); 

	//console.log('End of trial ', FLAGS.current_trial, '. TRIAL: ', TRIAL)
	FLAGS.current_trial++
	

} 
})(); 



</script>
</body>

<!-- ************ COMMENT SECTION ************ -->
<!-- This code uses generators & promises from ESM6 harmony to implement a state machine.  This is experimental and only supported on modern browsers (see http://caniuse.com/#feat=promises for full support).
The reasons for using this approach are twofold:
(1) Solving the inversion of control with the old way of using async callbacks in javascript (http://blog.getify.com/promises-part-2/)
(2) readability of the code (http://davidwalsh.name/async-generators)
->(1) makes exception handling much easier
->(2) makes the code easier to edit in the future:
		"The main strength of generators is that they provide a single-threaded, synchronous-looking code style, while allowing you to hide the asynchronicity away as an implementation detail. This lets us express in a very natural way what the flow of our program's steps/statements is without simultaneously having to navigate asynchronous syntax and gotchas."
As of 2014.12.01, generators are not supported in safari and not in iOS (even Chrome for iOS is limited to apple webkit).  Could transpile but better to use a native Chrome environment (i.e. android tablet).
// Load audio webkit, see http://middleearmedia.com/controlling-web-audio-api-oscillators/
// var audiocontext = new webkitAudioContext(); // Create audio container with webkit prefix
// In case you're wondering why you can't use the devicePixelRatio to determine the backing store size, the answer is that they aren't guaranteed to match. Despite presenting the same devicePixelRatio value, Chrome and Safari 6 can and do have entirely different approaches for the backing store size (and therefore the webkitBackingStorePixelRatio) on HiDPI devices. The net result is that we can't rely on devicePixelRatio to know how the browser is going to scale images that are written into the CANVAS.  http://www.html5rocks.com/en/tutorials/canvas/hidpi/
-->
<!-- ************ /COMMENT SECTION ************ -->

</html>